---
path: /home/creating-experiments/allocation
title: Allocating experiment audiences
description: This topic explains how to include specific groups of users in an experiment audience using audience allocation.
published: true
tags: ['population', 'audience', 'allocation', 'ab testing', 'experiment', 'experimentation', 'enterprise']
---

## Overview

This topic explains how to include specific groups of users in an experiment audience using audience allocation.

## Understanding experiment audiences

You have the option to only include a subset of users in your experiments, which gives you accurate experiment results more quickly. This subset of users is called your "experiment audience."

For example, imagine you plan to test alternate copy for your checkout button. You target all Canadian and US users with the `true` variation for the button, which shows the new, alternate copy, but you only want to run an experiment measuring click conversions for users in the United States.

To accomplish this, you would select the user targeting rule on the flag's **Targeting** tab that affects US-based users and de-select the rule that targets users in Canada. This limits the users who evaluate the flag to only those who are based in the United States.

You may want to refine your experiment audience for any of the following reasons:

- To run targeted experiments for a subset of your flag-targeted users.
- To exclude user groups whose events you do not need to measure. For example, users affected by 'Default' rules.
- To reduce the volume of users in an experiment.

## Creating experiment audiences

You determine the initial experiment audience when you create a new experiment. You must include at least two variations in the experiment for the experiment to be valid. To learn more, read [Building experiments](/home/creating-experiments#building-experiments).

### Using targeting rules

You can run an experiment on a flag's default rule, or you can create a custom experiment audience by selecting a specific flag targeting rule to include in your experiment. You can target by any user attribute you collect. To learn how, read [Targeting rules](/home/flags/targeting-rules).

### Allocating audiences

When you build your experiment, you can allocate all or a percentage of the user traffic that encounters a flag in an experiment. Audience allocation gives you flexibility when selecting your experiment audience and ensures accurate experiment results. LaunchDarkly analyzes only users that you choose to be part of the experiment.

If you decide to increase or decrease the number of users in an experiment, LaunchDarkly will create a new iteration of your experiment. To learn more, read [Starting experiment iterations](/home/creating-experiments#starting-experiment-iterations).

LaunchDarkly automatically performs checks on the allocation, to make sure that actual user traffic matches the allocation you set. To learn more, read [Understanding sample ratios](/home/analyzing-experiments/sample-ratios).

### Changing traffic allocation

When the number of users in your variations increases or decreases, LaunchDarkly properly reassigns users to different variations to prevent carryover bias. This method of managing your experiment audience is called "audience allocation." To learn more about carryover bias, read [Understanding variation reassignment](#understanding-variation-reassignment).

Here is an image of a flag's targeting rule with 20% of users included in the experiment:

![The user targeting section of a flag's "Targeting" tab with an active experiment.](experiment-flag-targeting-tab.png)

If you decide to start a new iteration of your experiment and increase or decrease the amount of traffic in your experiment audience, LaunchDarkly will automatically add or remove users to or from the variations using variation reassignment. To learn how to change the audience for a running experiment, read [Changing an experiment's audience](/home/analyzing-experiments/managing#changing-an-experiments-audience).

If you start a new iteration of your experiment but don't change the amount of traffic in your experiment audience, LaunchDarkly will not reassign users to different variations.

## Understanding variation reassignment

Experiments are subject to day-of-week or hour-of-day effects. For example, a user’s behavior on a website is often different depending on if they are visiting on a Saturday or a Monday. This can cause problems in properly computing experiment results if you use traffic from two different time frames when you increased the percent of traffic going to various users.

For example, say you allocated 6% of your traffic to your experiment and it included traffic from weekdays only, and later when you increase your allocated traffic to 30%, it also included traffic from weekends. Because you had more traffic on weekends, the data would overrepresent that traffic and you would get a biased result. You can avoid this by allowing "variation reassignment."

Here is an example of audience allocation using variation reassignment: first, you add an experiment to a flag with three variations: A, B, and C. You roll out the three variations to 6% of the users, while the remaining 94% receives the control, variation A. The control traffic is not part of the experiment nor its analysis.

Here is a visualization of the starting traffic allocation, with the control group on the right:

![An experiment audience with 6% in the experiment and 94% in the control group.](experiment-allocation-six-percent.png)

Next, you ramp up your experiment to 30% of traffic. This creates a new iteration of the experiment. In the new iteration, the 6% that were receiving variations A, B, and C have reverted to the control, variation A. The 30% allocated to the experiment is from new traffic.

Here is an example of the modified allocation, with the control group on both the left and right:

![An experiment audience with 30% in the experiment and 70% in the control group.](experiment-allocation-thirty-percent.png)

Finally, you roll out variations A and B to 50% of traffic each. This creates another iteration of the experiment, and the entire audience is reallocated randomly. For example, 0%-1% partition will not have the exact same set of users as the previous 0%-1% partition.

Here is an example of the allocation with no control group:

![An experiment audience with 100% in the experiment.](experiment-allocation-fifty-percent.png)

This new random assignment prevents carryover bias by ensuring that users from previous variations are evenly distributed between variations A and B.

### Using variation reassignment

It may seem counterintuitive to allow the experiment to reassign users to different variations, especially if you are used to the way rollouts work in LaunchDarkly outside of experimentation. However, allowing reassignment has advantages, provided the change you are experimenting on is not disruptive to users. In practice, this is the case for many experiments. A common example is "user-day experiments", which run for only one day at a time.

For experiments where users should not leave the variation they're initially allocated to, such as significant navigation menu changes or large user interface (UI) changes, you can disable variation reassignment. However, keeping users in the same variations incurs additional risk.

Using fresh traffic and freeing the previous ramp’s traffic prevents carry-over effects and ensures you don't run out of traffic for your experiment.

### Disabling variation reassignment

<Callout intent="alert">
<CalloutTitle>We do not recommend this option for the majority of use cases</CalloutTitle>
<CalloutDescription>

Allowing variation reassignment should be the default for your experiments. If you are unsure if you need to allow or disallow variation reassignment, we suggest you allow variation reassignment.

</CalloutDescription>
</Callout>

You should only rarely prevent users from switching variations during an experiment by disabling variation reassignment. You may want to disable variation reassignment for substantial changes, such as major navigation menu or UI changes. You can disable variation reassignment by clicking **Advanced**, then checking the **Prevent variation reassignment when increasing traffic** checkbox.

<Callout intent="warning">
<CalloutTitle>Traffic will be assigned to new variations if you stop an experiment</CalloutTitle>
<CalloutDescription>

Checking the **Prevent variation reassignment when increasing traffic** checkbox prevents variation reassignment only if you change the amount of traffic in your experiment audience by editing a running experiment using the experiment's **Edit** button. To learn more, read [Editing experiments](/home/analyzing-experiments/managing#editing-experiments).

If you instead use the **Stop** button to stop an experiment iteration, change the amount of traffic in your experiment audience, then start a new iteration, LaunchDarkly will still reshuffle traffic into new variations.

</CalloutDescription>
</Callout>

Here is an example of running an experiment with variation reassignment disabled: you add an experiment to a flag with three variations: A, B, and C. You roll out the three variations to 6% of the users, while the remaining 94% receives the control, variation A. The control traffic is not part of the experiment nor its analysis.

Here is a visualization of the starting traffic allocation, with the control group on the right:

![An experiment audience with 6% in the experiment and 94% in the control group.](experiment-allocation-six-percent.png)

Next, you ramp up your experiment to 30% of traffic. This creates a new iteration of the experiment. In the new iteration, the 6% that were receiving variations A, B, and C, continue to receive those variations, but are no longer included in the experiment nor its analysis. New traffic is used for the 30% allocated to the experiment.

Here is an example of the modified allocation, with the control group on the right and the original experiment audience on the left:

![An experiment audience with 6% no longer in the experiment, 30% in the experiment, and 64% in the control group.](experiment-allocation-thirty-percent-no-reshuffle.png)
